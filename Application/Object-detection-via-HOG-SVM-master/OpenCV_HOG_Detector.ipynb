{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "2 (2) found\n",
      "4 (2) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "2 (2) found\n",
      "4 (2) found\n",
      "2 (2) found\n",
      "4 (2) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "2 (2) found\n",
      "4 (2) found\n",
      "2 (2) found\n",
      "4 (2) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "2 (2) found\n",
      "4 (2) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n",
      "1 (1) found\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4d131ea2a76e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#running an infinite loop so that the process is run real time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# reading the frames produced from the webcam in 'img' an then returning them using the 'ret' function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mfound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwinStride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.05\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# describing the parameters of HOG and returning them as a Human found function in 'found'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mfound_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#filtering the found human... to further improve visualisation (uses Gaussian filter for eradication of errors produced by luminescence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Modified from OpenCV HOG person detector (should work straight off the bat)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "from glob import glob\n",
    "import itertools as it\n",
    "\n",
    "def inside(r, q):\n",
    "    rx, ry, rw, rh = r\n",
    "    qx, qy, qw, qh = q\n",
    "    return rx > qx and ry > qy and rx + rw < qx + qw and ry + rh < qy + qh\n",
    "\n",
    "def draw_detections(img, rects, thickness = 1):\n",
    "    for x, y, w, h in rects:\n",
    "        # the HOG detector returns slightly larger rectangles than the real objects.\n",
    "        # so we slightly shrink the rectangles to get a nicer output.\n",
    "        pad_w, pad_h = int(0.15*w), int(0.05*h)\n",
    "        cv2.rectangle(img, (x+pad_w, y+pad_h), (x+w-pad_w, y+h-pad_h), (0, 0, 255), thickness)\n",
    "\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector() )\n",
    "''' the above code uses a pretrained SVM via HOG descriptors provided by the open cv database.\n",
    "This database is limited to the training it has performed hence cannot be used in any other angle other than perp. to the centroid\n",
    "Thus if you want to implement the HOG + SVM method, you'll have to train your own SVM with your own data'''\n",
    "cap= cv2.VideoCapture(0)\n",
    "# the above code uses the OpenCV library to capture video frames from the camera: select 0 for the primary pc webcam & 1 for an external camera\n",
    "\n",
    "while True:\n",
    "    #running an infinite loop so that the process is run real time.\n",
    "    ret, img = cap.read() # reading the frames produced from the webcam in 'img' an then returning them using the 'ret' function.\n",
    "    found, w = hog.detectMultiScale(img, winStride=(16,16), padding=(32,32), scale=1.05) # describing the parameters of HOG and returning them as a Human found function in 'found'\n",
    "    found_filtered = [] #filtering the found human... to further improve visualisation (uses Gaussian filter for eradication of errors produced by luminescence.\n",
    "    for ri, r in enumerate(found):\n",
    "        for qi, q in enumerate(found):\n",
    "            if ri != qi and inside(r, q):\n",
    "                break\n",
    "            else:\n",
    "                found_filtered.append(r)\n",
    "        draw_detections(img, found) # using the predefined bounding box to encapsulate the human detected within the bounding box.\n",
    "        draw_detections(img, found_filtered, 3) # further filtering the box to improve visualisation.\n",
    "        print('%d (%d) found' % (len(found_filtered), len(found))) # this will produce the output of the number of humans found in the actual command box)\n",
    "    cv2.imshow('img', img) # finally showing the resulting image captured from the webcam.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break # defining a key to quit and stop all processes. The key is 'q'\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() # finally, destroying all open windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
