{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules:\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import pyramid_gaussian\n",
    "from skimage.io import imread\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import color\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import imutils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image # This will be used to read/modify images (can be done via OpenCV too)\n",
    "from numpy import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902\n",
      "1667\n",
      " Constructing training/testing split...\n",
      " Training Linear SVM classifier...\n",
      " Evaluating classifier on test data ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       325\n",
      "           1       0.76      0.74      0.75       189\n",
      "\n",
      "    accuracy                           0.82       514\n",
      "   macro avg       0.81      0.80      0.80       514\n",
      "weighted avg       0.82      0.82      0.82       514\n",
      "\n",
      "\n",
      " Execution time :  6.63 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_hog.npy']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define parameters of HOG feature extraction\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "threshold = .3\n",
    "\n",
    "\n",
    "# define path to images:\n",
    "\n",
    "pos_im_path = r\"INRIAPerson/pos/\" # This is the path of our positive input dataset\n",
    "# define the same for negatives\n",
    "neg_im_path= r\"INRIAPerson/negg/\"\n",
    "\n",
    "# read the image files:\n",
    "pos_im_listing = os.listdir(pos_im_path) # it will read all the files in the positive image path (so all the required images)\n",
    "neg_im_listing = os.listdir(neg_im_path)\n",
    "num_pos_samples = size(pos_im_listing) # simply states the total no. of images\n",
    "num_neg_samples = size(neg_im_listing)\n",
    "print(num_pos_samples) # prints the number value of the no.of samples in positive dataset\n",
    "print(num_neg_samples)\n",
    "data= []\n",
    "labels = []\n",
    "\n",
    "# compute HOG features and label them:\n",
    "\n",
    "for file in pos_im_listing: #this loop enables reading the files in the pos_im_listing variable one by one\n",
    "    img = Image.open(pos_im_path + file) # open the file\n",
    "    img = img.resize((64,128))\n",
    "    gray = img.convert('L') # convert the image into single channel i.e. RGB to grayscale\n",
    "    # calculate HOG for positive features\n",
    "    fd = hog(gray, orientations, pixels_per_cell, cells_per_block, block_norm='L2', feature_vector=True)# fd= feature descriptor\n",
    "    data.append(fd)\n",
    "    labels.append(1)\n",
    "    \n",
    "# Same for the negative images\n",
    "for file in neg_im_listing:\n",
    "    img= Image.open(neg_im_path + file)\n",
    "    img = img.resize((64,128))\n",
    "    gray= img.convert('L')\n",
    "    # Now we calculate the HOG for negative features\n",
    "    fd = hog(gray, orientations, pixels_per_cell, cells_per_block, block_norm='L2', feature_vector=True) \n",
    "    data.append(fd)\n",
    "    labels.append(0)\n",
    "# encode the labels, converting them from strings to integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "#%%\n",
    "# Partitioning the data into training and testing splits, using 80%\n",
    "# of the data for training and the remaining 20% for testing\n",
    "print(\" Constructing training/testing split...\")\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(\n",
    "\tnp.array(data), labels, test_size=0.20, random_state=42)\n",
    "#%% Train the linear SVM\n",
    "print(\" Training Linear SVM classifier...\")\n",
    "model = LinearSVC()\n",
    "\n",
    "#Mesure du temps d'execution\n",
    "start_time = time.time() \n",
    "\n",
    "#Entrainement du modèle\n",
    "model.fit(trainData, trainLabels)\n",
    "\n",
    "interval = time.time() - start_time\n",
    "\n",
    "#%% Evaluate the classifier\n",
    "print(\" Evaluating classifier on test data ...\")\n",
    "predictions = model.predict(testData)\n",
    "print(classification_report(testLabels, predictions))\n",
    "\n",
    "print('\\n Execution time : ', round(interval,2), 'sec')\n",
    "\n",
    "# Save the model:\n",
    "#%% Save the Model\n",
    "joblib.dump(model, 'model_hog.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902\n",
      "1667\n",
      " Constructing training/testing split...\n",
      " Training Linear SVM classifier...\n",
      " Evaluating classifier on test data ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80       325\n",
      "           1       0.67      0.61      0.64       189\n",
      "\n",
      "    accuracy                           0.75       514\n",
      "   macro avg       0.73      0.72      0.72       514\n",
      "weighted avg       0.74      0.75      0.74       514\n",
      "\n",
      "\n",
      " Execution time :  20.77 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeje/anaconda3/envs/TP-TIM/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_gray.npy']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define parameters of HOG feature extraction\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "threshold = .3\n",
    "\n",
    "\n",
    "# define path to images:\n",
    "\n",
    "pos_im_path = r\"INRIAPerson/pos/\" # This is the path of our positive input dataset\n",
    "# define the same for negatives\n",
    "neg_im_path= r\"INRIAPerson/negg/\"\n",
    "\n",
    "# read the image files:\n",
    "pos_im_listing = os.listdir(pos_im_path) # it will read all the files in the positive image path (so all the required images)\n",
    "neg_im_listing = os.listdir(neg_im_path)\n",
    "num_pos_samples = size(pos_im_listing) # simply states the total no. of images\n",
    "num_neg_samples = size(neg_im_listing)\n",
    "print(num_pos_samples) # prints the number value of the no.of samples in positive dataset\n",
    "print(num_neg_samples)\n",
    "data= []\n",
    "labels = []\n",
    "\n",
    "# compute HOG features and label them:\n",
    "\n",
    "for file in pos_im_listing: #this loop enables reading the files in the pos_im_listing variable one by one\n",
    "    img = Image.open(pos_im_path + file) # open the file\n",
    "    img = img.resize((64,128))\n",
    "    gray = img.convert('L') # convert the image into single channel i.e. RGB to grayscale\n",
    "    gray = np.array(gray)\n",
    "    gray = gray.reshape((8192,))\n",
    "    # calculate HOG for positive features\n",
    "    #fd = hog(gray, orientations, pixels_per_cell, cells_per_block, block_norm='L2', feature_vector=True)# fd= feature descriptor\n",
    "    data.append(gray)\n",
    "    labels.append(1)\n",
    "    \n",
    "# Same for the negative images\n",
    "for file in neg_im_listing:\n",
    "    img= Image.open(neg_im_path + file)\n",
    "    img = img.resize((64,128))\n",
    "    gray= img.convert('L')\n",
    "    gray = np.array(gray)\n",
    "    gray = gray.reshape((8192,))\n",
    "    # Now we calculate the HOG for negative features\n",
    "    #fd = hog(gray, orientations, pixels_per_cell, cells_per_block, block_norm='L2', feature_vector=True) \n",
    "    data.append(gray)\n",
    "    labels.append(0)\n",
    "# encode the labels, converting them from strings to integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "#%%\n",
    "# Partitioning the data into training and testing splits, using 80%\n",
    "# of the data for training and the remaining 20% for testing\n",
    "print(\" Constructing training/testing split...\")\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(\n",
    "\tnp.array(data), labels, test_size=0.20, random_state=42)\n",
    "#%% Train the linear SVM\n",
    "print(\" Training Linear SVM classifier...\")\n",
    "model = LinearSVC()\n",
    "\n",
    "#Mesure du temps d'execution\n",
    "start_time = time.time() \n",
    "\n",
    "#Entrainement du modèle\n",
    "model.fit(trainData, trainLabels)\n",
    "\n",
    "interval = time.time() - start_time\n",
    "\n",
    "#%% Evaluate the classifier\n",
    "print(\" Evaluating classifier on test data ...\")\n",
    "predictions = model.predict(testData)\n",
    "print(classification_report(testLabels, predictions))\n",
    "\n",
    "print('\\n Execution time : ', round(interval,2), 'sec')\n",
    "# Save the model:\n",
    "#%% Save the Model\n",
    "joblib.dump(model, 'model_gray.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
