{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications Projet HOG\n",
    "## Application 1 : Entrainement d'un SVM\n",
    "#### Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage.transform import pyramid_gaussian\n",
    "from skimage.io import imread\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import color\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import imutils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image # This will be used to read/modify images (can be done via OpenCV too)\n",
    "from numpy import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du SVM avec les descripteurs de HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902\n",
      "1667\n",
      " Constructing training/testing split...\n",
      " Training Linear SVM classifier...\n",
      " Evaluating classifier on test data ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       325\n",
      "           1       0.76      0.74      0.75       189\n",
      "\n",
      "    accuracy                           0.82       514\n",
      "   macro avg       0.81      0.80      0.80       514\n",
      "weighted avg       0.82      0.82      0.82       514\n",
      "\n",
      "\n",
      " Data preprocessing time :  31.36 sec\n",
      "\n",
      " Execution time :  5.13 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_hog.npy']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define parameters of HOG feature extraction\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "threshold = .3\n",
    "\n",
    "\n",
    "# define path to images:\n",
    "pos_im_path = r\"INRIAPerson/pos/\" # This is the path of our positive input dataset\n",
    "neg_im_path= r\"INRIAPerson/negg/\" # This is the path of our negative input dataset\n",
    "\n",
    "\n",
    "# read the image files:\n",
    "pos_im_listing = os.listdir(pos_im_path) # it will read all the files in the positive image path (so all the required images)\n",
    "neg_im_listing = os.listdir(neg_im_path)\n",
    "num_pos_samples = size(pos_im_listing) # simply states the total no. of images\n",
    "num_neg_samples = size(neg_im_listing)\n",
    "print(num_pos_samples) # prints the number value of the no.of samples in positive dataset\n",
    "print(num_neg_samples)\n",
    "data= []\n",
    "labels = []\n",
    "\n",
    "\n",
    "# data preprocessing time measurement (begin)\n",
    "start_time = time.time()  \n",
    "\n",
    "\n",
    "# compute HOG features and label them:\n",
    "for file in pos_im_listing: #this loop enables reading the files in the pos_im_listing variable one by one\n",
    "    img = Image.open(pos_im_path + file) # open the file\n",
    "    img = img.resize((64,128)) # resize the image to fit with the model\n",
    "    gray = img.convert('L') # convert the image into single channel i.e. RGB to grayscale\n",
    "    # calculate HOG for positive features\n",
    "    fd = hog(gray, orientations, pixels_per_cell, cells_per_block, block_norm='L2', feature_vector=True)# fd= feature descriptor\n",
    "    data.append(fd)\n",
    "    labels.append(1)\n",
    "    \n",
    "# Same for the negative images\n",
    "for file in neg_im_listing:\n",
    "    img= Image.open(neg_im_path + file)\n",
    "    img = img.resize((64,128))\n",
    "    gray= img.convert('L')\n",
    "    # Now we calculate the HOG for negative features\n",
    "    fd = hog(gray, orientations, pixels_per_cell, cells_per_block, block_norm='L2', feature_vector=True) \n",
    "    data.append(fd)\n",
    "    labels.append(0)\n",
    "    \n",
    "# data preprocessing time measurement (end)\n",
    "interval = time.time() - start_time\n",
    "\n",
    "\n",
    "# encode the labels, converting them from strings to integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "\n",
    "# Partitioning the data into training and testing splits, 80% for training and 20% for testing\n",
    "print(\" Constructing training/testing split...\")\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(data), labels, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "# Train the linear SVM\n",
    "print(\" Training Linear SVM classifier...\")\n",
    "model = LinearSVC()\n",
    "\n",
    "\n",
    "# execution time measurement (begin)\n",
    "start_time = time.time() \n",
    "\n",
    "\n",
    "# model fitting\n",
    "model.fit(trainData, trainLabels)\n",
    "\n",
    "\n",
    "# execution time measurement (end)\n",
    "interval_2 = time.time() - start_time\n",
    "\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\" Evaluating classifier on test data ...\")\n",
    "predictions = model.predict(testData)\n",
    "print(classification_report(testLabels, predictions))\n",
    "\n",
    "# Affichage des temps de prétraitement et d'éxécution\n",
    "print('\\n Data preprocessing time : ', round(interval,2), 'sec')\n",
    "print('\\n Execution time : ', round(interval_2,2), 'sec')\n",
    "\n",
    "\n",
    "# Save the model:\n",
    "joblib.dump(model, 'model_hog.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du SVM avec des images en nuances de gris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902\n",
      "1667\n",
      " Constructing training/testing split...\n",
      " Training Linear SVM classifier...\n",
      " Evaluating classifier on test data ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80       325\n",
      "           1       0.67      0.61      0.64       189\n",
      "\n",
      "    accuracy                           0.75       514\n",
      "   macro avg       0.73      0.72      0.72       514\n",
      "weighted avg       0.74      0.75      0.74       514\n",
      "\n",
      "\n",
      " Data preprocessing time :  27.87 sec\n",
      "\n",
      " Execution time :  20.49 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeje/anaconda3/envs/TP-TIM/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_gray.npy']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define parameters of HOG feature extraction\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "threshold = .3\n",
    "\n",
    "\n",
    "# define path to images:\n",
    "pos_im_path = r\"INRIAPerson/pos/\" # This is the path of our positive input dataset\n",
    "neg_im_path= r\"INRIAPerson/negg/\" # This is the path of our negative input dataset\n",
    "\n",
    "\n",
    "# read the image files:\n",
    "pos_im_listing = os.listdir(pos_im_path) # it will read all the files in the positive image path (so all the required images)\n",
    "neg_im_listing = os.listdir(neg_im_path)\n",
    "num_pos_samples = size(pos_im_listing) # simply states the total no. of images\n",
    "num_neg_samples = size(neg_im_listing)\n",
    "print(num_pos_samples) # prints the number value of the no.of samples in positive dataset\n",
    "print(num_neg_samples)\n",
    "data= []\n",
    "labels = []\n",
    "\n",
    "\n",
    "# data preprocessing time measurement (begin)\n",
    "start_time = time.time()  \n",
    "\n",
    "\n",
    "# compute HOG features and label them:\n",
    "for file in pos_im_listing: #this loop enables reading the files in the pos_im_listing variable one by one\n",
    "    img = Image.open(pos_im_path + file) # open the file\n",
    "    img = img.resize((64,128)) # resize the image to fit with the model\n",
    "    gray = img.convert('L') # convert the image into single channel i.e. RGB to grayscale\n",
    "    gray = np.array(gray)\n",
    "    gray = gray.reshape((8192,)) #reshape the image to fit for the model\n",
    "    data.append(gray)\n",
    "    labels.append(1)\n",
    "    \n",
    "# Same for the negative images\n",
    "for file in neg_im_listing:\n",
    "    img= Image.open(neg_im_path + file)\n",
    "    img = img.resize((64,128))\n",
    "    gray= img.convert('L')\n",
    "    gray = np.array(gray)\n",
    "    gray = gray.reshape((8192,))\n",
    "    data.append(gray)\n",
    "    labels.append(0)\n",
    "    \n",
    "\n",
    "# data preprocessing time measurement (end)\n",
    "interval = time.time() - start_time\n",
    "\n",
    "\n",
    "# encode the labels, converting them from strings to integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "\n",
    "# Partitioning the data into training and testing splits, 80% for training and 20% for testing\n",
    "print(\" Constructing training/testing split...\")\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(data), labels, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "# Train the linear SVM\n",
    "print(\" Training Linear SVM classifier...\")\n",
    "model = LinearSVC()\n",
    "\n",
    "\n",
    "# execution time measurement (begin)\n",
    "start_time = time.time() \n",
    "\n",
    "\n",
    "# model fitting\n",
    "model.fit(trainData, trainLabels)\n",
    "\n",
    "\n",
    "# execution time measurement (end)\n",
    "interval_2 = time.time() - start_time\n",
    "\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\" Evaluating classifier on test data ...\")\n",
    "predictions = model.predict(testData)\n",
    "print(classification_report(testLabels, predictions))\n",
    "\n",
    "# Affichage des temps de prétraitement et d'éxécution\n",
    "print('\\n Data preprocessing time : ', round(interval,2), 'sec')\n",
    "print('\\n Execution time : ', round(interval_2,2), 'sec')\n",
    "\n",
    "\n",
    "# Save the model:\n",
    "joblib.dump(model, 'model_gray.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion pour l'application 1:\n",
    "\n",
    "- Avec les descipteurs de HOG\n",
    "    - meilleur précision du modèle\n",
    "    - meilleur temps d'apprentissage du modèle\n",
    "- Avec les images en nuances de gris\n",
    "    - meilleur temps de prétraitement des données (mais pas aussi significatif que le temps d'apprentissage du modèle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application 2 : Détection de personne(s) en mouvement / piétons\n",
    "#### Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La fonction commentée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myHogDetecttion(videoPATH, output_name, output_fps, output_format, win_size, padd_size, scale_value):\n",
    "    \"\"\"Detection of person on video with hog.detectMultiScale from OpenCV\"\"\"\n",
    "    def inside(r, q):\n",
    "        \"\"\"Return the coordinates of the rectangle wich contain the detection\"\"\"\n",
    "        rx, ry, rw, rh = r\n",
    "        qx, qy, qw, qh = q\n",
    "        return rx > qx and ry > qy and rx + rw < qx + qw and ry + rh < qy + qh\n",
    "\n",
    "    def draw_detections(img, rects, thickness = 1):\n",
    "        \"\"\"Draw the rectangle wich contain the detection on the picture\"\"\"\n",
    "        for x, y, w, h in rects:\n",
    "            # the HOG detector returns slightly larger rectangles than the real objects.\n",
    "            # so we slightly shrink the rectangles to get a nicer output.\n",
    "            pad_w, pad_h = int(0.15*w), int(0.05*h)\n",
    "            cv2.rectangle(img, (x+pad_w, y+pad_h), (x+w-pad_w, y+h-pad_h), (0, 0, 255), thickness)\n",
    "    \n",
    "    # load the linear SVM Detector from HOG from OpenCV\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "    \n",
    "    # Start the processing on the video\n",
    "    cap = cv2.VideoCapture(videoPATH) # load the video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID') # initialize the encoder\n",
    "    out = cv2.VideoWriter(output_name + '.avi',fourcc, output_fps, output_format) # initialize parameters for the output video\n",
    "    \n",
    "    # processing each image of the video\n",
    "    while True:\n",
    "        ret, frame = cap.read() #get the next image on the buffer\n",
    "        if ret == True: # frame contain an image / else this is the end of the video\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE) # 90° rotation because it is a portrait video\n",
    "            frame = cv2.resize(frame,output_format,fx=0,fy=0, interpolation = cv2.INTER_CUBIC) #resize to match with the output video\n",
    "            \n",
    "            # Most important line : detection of human body on the multiscale with the given parameters \n",
    "            found, w = hog.detectMultiScale(frame, winStride=win_size, padding=padd_size, scale=scale_value)\n",
    "            \n",
    "            found_filtered = [] \n",
    "            # the next two loops draw the detections rectangles on the image\n",
    "            for ri, r in enumerate(found):\n",
    "                for qi, q in enumerate(found):\n",
    "                    if ri != qi and inside(r, q):\n",
    "                        break\n",
    "                    else:\n",
    "                        found_filtered.append(r)\n",
    "                draw_detections(frame, found)\n",
    "                draw_detections(frame, found_filtered, 3) # further filtering the box to improve visualisation.\n",
    "            out.write(frame) # write the image on the output video\n",
    "        else:\n",
    "            break\n",
    "    cap.release() # release the buffer\n",
    "    out.release() # end of the output video\n",
    "    cv2.destroyAllWindows() # release the buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time :  4.75 sec\n",
      "Video duration : 7 sec\n"
     ]
    }
   ],
   "source": [
    "#Initialisation of the parameters\n",
    "vp = './Videos/VID_20201122_193855.mp4'\n",
    "out_name, out_fps, out_size = 'output_detection1', 30, (128,256)\n",
    "w_s, p_s, s_v = (4,4), (16,16), 1.05\n",
    "\n",
    "# Execution time measurement\n",
    "start_time = time.time() \n",
    "\n",
    "#Detection with Hog\n",
    "myHogDetecttion(vp, out_name, out_fps, out_size, w_s, p_s, s_v)\n",
    "\n",
    "interval = time.time() - start_time\n",
    "print ('Execution time : ', round(interval,2), 'sec')\n",
    "print('Video duration : 7 sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time :  6.89 sec\n",
      "Video duration : 8 sec\n"
     ]
    }
   ],
   "source": [
    "#Initialisation of the parameters\n",
    "vp = './Videos/VID_20201122_193936.mp4'\n",
    "out_name, out_fps, out_size = 'output_detection2', 30, (256,512)\n",
    "w_s, p_s, s_v = (8,8), (16,16), 1.06\n",
    "\n",
    "#Execution time measurement\n",
    "start_time = time.time() \n",
    "\n",
    "#Detection with Hog\n",
    "myHogDetecttion(vp, out_name, out_fps, out_size, w_s, p_s, s_v)\n",
    "\n",
    "interval = time.time() - start_time  \n",
    "print ('Execution time : ', round(interval,2), 'sec')\n",
    "print('Video duration : 8 sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time :  19.45 sec\n",
      "Video duration : 20 sec\n"
     ]
    }
   ],
   "source": [
    "#Initialisation of the parameters\n",
    "vp = './Videos/VID_20201122_194028.mp4'\n",
    "out_name, out_fps, out_size = 'output_detection3', 30, (256,512)\n",
    "w_s, p_s, s_v = (8,8), (16,16), 1.05\n",
    "\n",
    "#Execution time measurement\n",
    "start_time = time.time() \n",
    "\n",
    "#Detection with Hog\n",
    "myHogDetecttion(vp, out_name, out_fps, out_size, w_s, p_s, s_v)\n",
    "\n",
    "interval = time.time() - start_time\n",
    "print ('Execution time : ', round(interval,2), 'sec')\n",
    "print('Video duration : 20 sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time :  4.18 sec\n",
      "Video duration : 5 sec\n"
     ]
    }
   ],
   "source": [
    "#Initialisation of the parameters\n",
    "vp = './Videos/VID_20201122_194121.mp4'\n",
    "out_name, out_fps, out_size = 'output_detection4', 30, (256,512)\n",
    "w_s, p_s, s_v = (8,8), (16,16), 1.08\n",
    "\n",
    "#Execution time measurement\n",
    "start_time = time.time() \n",
    "\n",
    "#Detection with Hog\n",
    "myHogDetecttion(vp, out_name, out_fps, out_size, w_s, p_s, s_v)\n",
    "\n",
    "interval = time.time() - start_time  \n",
    "print ('Execution time : ', round(interval,2), 'sec')\n",
    "print('Video duration : 5 sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion pour l'application 2:\n",
    "\n",
    "Grâce à l'ajustement judicieux des paramètres en entrée de la fonction on arrive à faire de la détection \"en temp réel\".\n",
    "\n",
    "**Remarque :** en ajustant les paramètres afin d'obtenir une détection plus précise (bien expliqué sur cette page : https://www.pyimagesearch.com/2015/11/16/hog-detectmultiscale-parameters-explained/), le résultat est vraiment concluant !\n",
    "\n",
    "**Remarque 2 :** les temps d'executions sont propres à chaque machine, il faut donc ajuster les paramètres en fonction de sa machine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
